<!DOCTYPE html>
<html lang="en">
<head>

	<!-- Basic Page Needs
	–––––––––––––––––––––––––––––––––––––––––––––––––– -->
	<meta charset="utf-8">
	<title>Lisa Jin | Projects</title>
	<meta name="description" content="">
	<meta name="author" content="">

	<!-- Mobile Specific Metas
	–––––––––––––––––––––––––––––––––––––––––––––––––– -->
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- FONT
	–––––––––––––––––––––––––––––––––––––––––––––––––– -->
	<link href="//fonts.googleapis.com/css?family=Raleway|Playfair+Display" rel="stylesheet" type="text/css">

	<!-- CSS
	–––––––––––––––––––––––––––––––––––––––––––––––––– -->
	<link rel="stylesheet" href="static/css/normalize.css">
	<link rel="stylesheet" href="static/css/skeleton.css">
	<link rel="stylesheet" href="static/css/main.css">
	<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

	<!-- Favicon
	–––––––––––––––––––––––––––––––––––––––––––––––––– -->
	<link rel="icon" type="image/png" href="static/images/favicon.png">
</head>
<body>

<!-- Primary Page Layout
–––––––––––––––––––––––––––––––––––––––––––––––––– -->
<div class="container">
	<div class="row">
		<div class="one-half column">
			<h4>Projects</h4>
		</div>
		<div class="one-half column">
			<h6>
				<a class="nav-link u-pull-right" href="static/LisaJin_CV.pdf" target="_blank">CV</a>
				<a class="nav-link u-pull-right" href="index.html">Home</a>
			</h6>
		</div>
	</div>
	<div class="row project-section">
		<div class="four columns">
			<p><strong>Advisor</strong>: <a href="//feng-lab.github.io" target="_blank">Linqing Feng</a></p>
			<a class="button" href="//github.com/lisjin/dcan-tensorflow" target="_blank">Code</a>
		</div>
		<div class="eight columns">
			<h6><strong>DCAN for Cell Nuclei Image Segmentation</strong></h6>
			<p>I was supported by <a href="//www.eecs.umich.edu/ipan/" target="_blank">NSF IPAN</a> to work with Dr. Linqing Feng at KIST. We were interested in automating cell segmentation to study micro-scale brain connectivity. This is crucial to efficiently analyze large volumes of electron microscopy (EM) images of regions such as the hippocampus. To test the efficacy of such a method, I implemented TensorFlow code for the DCAN model on human U2OS cell <a href="//data.broadinstitute.org/bbbc/BBBC006/" target="_blank">images</a>.</p>
			<p><a href="//arxiv.org/pdf/1604.02677.pdf" target="_blank">DCAN</a> by Chen et al. builds upon the fully convolutional network (<a href="//arxiv.org/pdf/1411.4038.pdf" target="_blank">FCN</a>), in which <i>semantic</i> insight of deeper layers is combined with <i>locality</i> details of shallower layers. This end-to-end network can make per-pixel predictions for tasks like semantic segmentation.</p>
		</div>
	</div>
	<div class="row project-section">
		<div class="four columns">
			<p><strong>Advisor</strong>: <a href="//web.eecs.umich.edu/~dkoutra/" target="_blank">Danai Koutra</a></p>
			<a class="button" href="//poloclub.gatech.edu/idea2017/papers/p40-jin.pdf" target="_blank">Paper</a>
			<a class="button" href="//poloclub.gatech.edu/idea2017/slides/poster_Jin.pdf" target="_blank">Poster</a>
			<a class="button" href="//github.com/lisjin/eco-viz" target="_blank">Code</a>
		</div>
		<div class="eight columns">
			<h6><strong>ECOviz: Comparative Visualization of Time-Evolving Network Summaries</strong></h6>
			<p>Time-evolving graphs can be observed in a variety of domains, such as neuroscience and sociology. In connectomics, we can infer temporal networks from fMRI data; the nodes are voxels (volume units of neurons) and the edges are their thresholded associations. How can we track the evolution of domain-specific communities in such graphs?</p>
			<p>ECOviz is a system that <i>summarizes</i> and <i>visualizes</i> temporal network changes in a semi-supervised manner. Due to the small-worldness of brain networks, we used a subset of labeled nodes to inform <a href="//pdfs.semanticscholar.org/2448/9085f90aa5d262c21ef66c33dabaf413667e.pdf" target="_blank">TimeCrunch</a>, a dynamic graph summarization algorithm. In addition to showing the topology of summary structures, ECOviz allows users to compare the effects of preprocessing parameters (i.e., threshold and time interval granularity).</p>
		</div>
	</div>
	<div class="row project-section">
		<div class="four columns">
			<p><strong>Advisor</strong>: <a href="//www.andrewdeorio.com" target="_blank">Andrew DeOrio</a></p>
			<p><strong>Sponsors</strong>: <a href="//medicine.umich.edu/dept/human-genetics/dana-schlegel-ms-mph-cgc" target="_blank">Dana Schlegel</a>, <a href="//medicine.umich.edu/dept/ophthalmology/k-thiran-jayasundera-md-facs-frcsc-franzco" target="_blank">Thiran Jayasundera</a></p>
			<p><strong>Collaborators</strong>: Ajaay Chandrasekaran, Edmond Cunningham, Levin Kim, Wenlu Yan, Xinghai Zhang, Yaman Abdulhak</p>
			<a class="button" href="static/MDP_DesignExpo.pdf" target="_blank">Poster</a>
		</div>
		<div class="eight columns">
			<h6><strong>Cloud-Based Ocular Disease Diagnosis</strong></h6>
			<p>Sponsored by the <a href="//www.umkelloggeye.org" target="_blank">Kellogg Eye Center</a>, this was a two-semester project in the Multidisciplinary Design Program (<a href="//mdp.engin.umich.edu" target="_blank">MDP</a>). Retinal dystrophies are inheritable disorders that require expensive genetic tests and medical expertise to diagnose. Given patient inheritance and history data, we built a web app with a data-driven model to predict retinal dystrophy diagnosis.</p>
			<p>I developed the web app prototype (Python Flask, PostgreSQL) to input patient data and visualize aggregate statistics of the model output. The model first predicted inheritance pattern, then paired this with patient history to output the final diagnosis via an RBF kernel SVM (<i>n</i> = 104).</p>
		</div>
	</div>
	<div class="row project-section">
		<div class="four columns">
			<p><strong>Advisor</strong>: <a href="//lsa.umich.edu/psych/people/faculty/junz.html" target="_blank">Jun Zhang</a></p>
			<p><strong>Collaborator</strong>: Yinbin Lei</p>
			<a class="button" href="static/FCA_Report.pdf" target="_blank">Report</a>
			<a class="button" href="//github.com/lisjin/fca-viz" target="_blank">Code</a>
		</div>
		<div class="eight columns">
			<h6><strong>Visualization of Formal Concepts</strong></h6>
			<p>Under Prof. Jun Zhang and visiting faculty Yinbin Lei, this was an independent study project in the department of psychology. Though algorithms to extract concept hierarchies exist, I contributed code to <i>visualize</i> and <i>query</i> the computed lattice through set operations. This work was motivated by analysis of concept formation data.</p>
			<p>Formal concept analysis (FCA) is a method for deriving a concept hierarchy from a table of object-attribute relations. A formal concept is composed of a set of objects and their attributes. Concepts can be partially ordered into a lattice, or hierarchy, such that edges represents set closures.</p>
		</div>
	</div>
</div>

<!-- JS
–––––––––––––––––––––––––––––––––––––––––––––––––– -->
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-89614396-2', 'auto');
	ga('send', 'pageview');
</script>

<!-- End Document
–––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
